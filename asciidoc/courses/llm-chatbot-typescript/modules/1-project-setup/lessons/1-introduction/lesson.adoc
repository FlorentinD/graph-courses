= Introduction
:type: lesson
:order: 1

To get you started, we have link:https://github.com/neo4j-graphacademy/llm-chatbot-typescript[created a simple Chatbot interface^].
When you first get the project up and running, it will simply repeat your messages back to you.

But as you progress through the course, you will build the functionality to turn the Chatbot into an _intelligent_ movie recommendation assistant.
It will use the data held in a Neo4j database to improve the responses generated by an LLM.

First, let's take a look at the technology choices we have chosen.


== An introduction to Next.js

We have chosen to implement the chatbot using link:https://nextjs.org/[Next.js^].
You may be familiar with Next.js as a leading framework that extends the latest React features to enable developers to build full-stack applications.

The repository was originally link:https://github.com/vercel/next.js/tree/canary/packages/create-next-app[created with `create-next-app`^] and we have added link:https://tailwindcss.com/docs/guides/nextjs[TailwindCSS^] for presentation.

The front-end UI code creates a chatbot that uses link:https://github.com/neo4j-graphacademy/llm-chatbot-typescript/blob/main/src/hooks/chat.ts[a React hook^] to send an HTTP POST that triggers a chat module.

// TODO: Add screenshot

== LLM Integration with Langchain

At the start of the course, the AI assistant simply _repeats_ the user input.
But this AI assistant will become smarter as we write the code for it to communicate with an LLM.

If you have link:/courses/llm-fundamentals/[completed the Neo4j & LLM Fundamentals course^], you will be familiar with Langchain.
link:https://langchain.com[LangChain^] is an open-source framework designed to accelerate the development of LLM applications.
We have chosen Langchain because it provides a flexible base to test LLMs, and out-of-the-box chains for performing complex tasks.

Although we have chosen Streamlit, you will be able to use these components with the backend framework of your choice.

Although the link:/courses/llm-fundamentals/[Neo4j & LLM Fundamentals course^] covers the Python library and the code samples may differ, the overall concepts used in the TypeScript library are identical.


== LLMs from OpenAI

We have included instructions to integrate the Chatbot with link:https://openai.com[OpenAI's] Large Language Models.

OpenAI has gained prominence through its Generative Pretrained Transformer (GPT) series. GPT models are trained on vast datasets to generate text that mimics human writing. The release of GPT-3, and subsequently GPT-4, showcased improvements in language understanding and generation, increasing their application in various industries. The practical utility of these models in tasks like writing assistance, programming, and language translation has led to widespread adoption and attention.

You are by no means restricted to OpenAI, however.
The hands-on challenges in this course are LLM-agnostic and you are free to use one of the 60+ supported LLMs.

[TIP]
.Open-Source Alternatives
====
If you are looking for an open-source alternative, we recommend that you link:https://github.com/docker/genai-stack/[take a look at the GenAI Stack^].
The GenAI Stack consists of link:https://langchain.com[LangChain^] applications connecting to LLMs served by link:https://https://ollama.ai/[Ollama^], run within link:https://docker.com[Docker^] containers and backed by a Neo4j database.
====


== Complete the course Local or Online

In the next lesson, you will set up your project.
You can either clone or download the repository and complete the exercises locally, or you can use the **Open in Gitpod** buttons to complete the challenges using an Online IDE.


== Ready for launch?

Click the button below to mark this lesson as read.
We will then advance to the next lesson where we will get the project up and running.


read::Lesson Read[]


[.summary]
== Summary

In this lesson, we introduced you to the course.

In the next lesson, you will set your secrets and get the project up and running.
