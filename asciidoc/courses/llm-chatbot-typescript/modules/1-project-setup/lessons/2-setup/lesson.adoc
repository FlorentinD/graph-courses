= Project Setup
:type: lesson
:order: 2
:disable-cache: true
:lab-filename: bot.py
:lab: {repository-blob}/main/{lab-filename}

Let's start by getting the project up and running.

If you plan to complete the course using the online IDE, you can skip to link:#explore[Exploring the `app/` folder].

== Local install

To run the project locally, you need to install the project dependencies.

[TIP]
.Online Labs
====
If you prefer, you can use the buttons on each lesson to complete the code in an Online IDE provided by link:https://gitpod.io[GitPod^].
To use GitPod, you will need to register with a Github, Gitlab or BitBucket account.

lab::Explore Repository in GitPod[]
====

=== Node.js

To run the project, you will need Node.js installed locally.
We have designed the project to work with Node.js **v20.11.x0 LTS**.

To install Node.js, follow the link:https://nodejs.org/[installation steps on nodejs.org^].

You can verify your Node.js version by running the following command.

[source,sh]
.Verify Node.js Version
node --version



=== Setting up the Project

The link:https://github.com/neo4j-graphacademy/llm-chatbot-typescript[project repository is hosted on Github^].

You can use the GitHub UI or CLI to clone the repository or link:https://github.com/neo4j-graphacademy/llm-chatbot-typescript/archive/refs/heads/main.zip[download a ZIP archive^].
We recommend https://github.com/neo4j-graphacademy/llm-chatbot-typescript/fork[forking the repository] so you have a personal copy for future reference.

To clone the repository using the `git` CLI, you can run the following command.

[source,sh]
.Clone the Repository
----
git clone https://github.com/neo4j-graphacademy/llm-chatbot-typescript
----

=== Installing Dependencies

You can review the dependenies required to run the project in the link:{repository-blob}/main/package.json[`package.json`] file in the project root.

Too install the dependencies, you can run the `npm install` command.

[source,sh]
.Install Depencencies
npm install --include=dev


=== Starting the App


To start the app, run the `npm run dev` command.

[source,sh]
.Run the Next.js app
----
npm run dev
----

This command command will start a server on http://localhost:3000.
Once you have run the command, you should see the following interface.

// TODO: Image of working app
image::images/working-app.png[GraphAcademy Chatbot App Interface with an introductory message from the assistant and a box to send a message.]

When you send a message, the message will be rendered in a box aligned to the right of the screen, similar to other chat apps.
When a message is received from the API it will be displayed to the left of the screen.


[#explore]
== Exploring the `app/` folder

We have purposely kept the code simple, so you can focus on the LLM integration.

The `app/` folder contains the general application code, plus some custom CSS.
The `components/` folder contains React components that are used to display the chat interface including the form, message and a _thinking_ indicator.

The `hooks/` folder contains the React hook that holds the chatbot's state and enables the chat interface.
When the form is submitted, the application state is updated to show the loading indicator, send an HTTP POST request to the `/api/chat/` endpoint where the response is generated.
When a response is received, the message is appended to the state and displayed on screen.


=== Handling Submissions

You will edit the route `handler` function in the `pages/api/chat.ts` file.

As you clone the repository, the initial route handler will use `setTimeout` to delay for a second before returning a JSON object containing the same message.

Your first step will be to create an Agent that replaces this functionality with a call to an LLM.

[%collapsible]
.View the initial route handler function
====
You will

.Stop copying me!
[source,python]
----
include::{repository-raw}/main/src/pages/api/chat.ts[]
----
====

// TODO: video?


== Check Your Understanding

include::questions/1-server.adoc[leveloffset=+1]

[.summary]
== Summary

In this lesson, you obtained a copy of the course code, installed the dependency and used the `npm run dev` command to start the app.

In the next module, you will start writing the code to interact with the LLM.
