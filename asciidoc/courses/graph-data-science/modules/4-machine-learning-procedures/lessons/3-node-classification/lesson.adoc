= Native Projections
:type: quiz

// [.video]
// video::xxxx[youtube,width=560,height=315]


//----
//CALL gds.graph.drop('proj');
//CALL gds.beta.model.drop('nc-pipeline-model');
//CALL gds.beta.pipeline.drop('pipe');
//----

[.transcript]
== Introduction
In this lesson you will learn how to use node classification in GDS.  This includes configuring and executing the pipeline as well as how to make predictions with the resulting modeling object.

=== Node Classification Pattern in GDS
Below is an illustration of the high level node classification pattern in GDS, going from a projected graph through various steps to finally registering a model and making predictions on your data.


image::images/nc-piepline-flow.png[title="Node Classification", 1600]

In practice, steps 1-6, the training steps, will be executed automatically by the pipeline. You will just be responsible for providing configuration and hyperparameters for them. So at a high level, you’re workflow will like the following for node classification, this will be the same for link prediction as well:

. project a graph and configure the pipeline (the order doesn’t matter)
. Execute the pipeline with a `train` command.
. Predict on a projected graph with the `predict` command.  The predictions can then be written back to the database if desired using graph write operations.

=== Example: Predicting Movie Genre with Node Classification

==== Setting up the Problem

For this example, we will train a model to predict which movies in the graph are comedies.  A comedy is defined as any movie which has a `Genre` of "Comedy".

`Genre` is currently represented by its own node in the graph.  For this problem we need it represented as a property of the  `Movie` node.  For demonstration purposes we will assign an `isComedy` property which is 1 if the Movie is a comedy and 0 otherwise.

----
MATCH(m:Movie)-[:IN_GENRE]->(g)
WITH m , collect(g.name) AS genres
SET m.cls = toInteger('Children' IN genres)
RETURN count(m), m.cls
----

Let’s also setup a hold-out sample for this problem so we can see how the model predicts after it is trained. To do this we will add labels based on `year` like so.

----
MATCH(m:Movie)
WHERE m.year >= 2010
    AND m.year < 2015
    AND m.runtime IS NOT NULL
    AND m.imdbRating IS NOT NULL
SET m:TrainMovie
RETURN count(m)
----

----
MATCH(m:Movie)
WHERE m.year > = 2015
SET m:HoldOutMovie
RETURN count(m)
----

Now we will project the graph using just the `TrainMovie` nodes for movies.  Movies have some node properties, such as revenue, and budget which we will include as they may turn out to be informative features.

Let’s also run some node embedding prior to pipeline configuration.  Lets Run one FastRP embedding on the `RATING` relationships then another on the `ACTED_IN` and `DIRECTED` relationships.

----
CALL gds.graph.project('proj',
    {
        Actor:{},
        TrainMovie:{ properties: ['cls', 'imdbRating', 'runtime']}
    },
    {
        ACTED_IN:{},
        HAD_ACTOR:{type:'ACTED_IN', orientation:'REVERSE'}
    }
);

CALL gds.alpha.collapsePath.mutate('proj',
  {
    relationshipTypes: ['ACTED_IN', 'HAD_ACTOR'],
    allowSelfLoops: false,
    mutateRelationshipType: 'SHARES_ACTOR_WITH'
  }
) YIELD relationshipsWritten;
----



==== Configure the Pipeline

The configuration steps will roughly follow the the steps in the [REFERENCE DIAGRAM]

. Create the Pipeline
. Add Node Properties
. Select Node Properties as Features
. Configure Node Splits - The data splitting into train, test, and feature-input steps
. Add Model Candidates

To get started, create the pipeline by running the following command

----
CALL gds.beta.pipeline.nodeClassification.create('pipe')
----

Once that is complete we will add node properties.  A node classification pipeline can execute one or several GDS algorithms in mutate mode that create node properties in the projection.

For our problem, let’s do a few things

First, FastRP embeddings winch will encapsulate the locality of movie nodes in the graph

----
CALL gds.beta.pipeline.nodeClassification.addNodeProperty('pipe', 'fastRP', {
  embeddingDimension: 128,
  mutateProperty:'embedding'
})
YIELD name, nodePropertySteps;
----

We can also add degree centrality which will measure the number of other movies with which actors are shared.

----
CALL gds.beta.pipeline.nodeClassification.addNodeProperty('pipe', 'degree', {
  mutateProperty:'degree'
})
YIELD name, nodePropertySteps;
----

Lastly we will scale the runtime property which is good practice for properties like this one that are relatively high magnitude

----
CALL gds.beta.pipeline.nodeClassification.addNodeProperty('pipe', 'alpha.scaleProperties', {
  nodeProperties: ['runtime'],
    scaler: 'Log',
  mutateProperty:'logRuntime'
})
YIELD name, nodePropertySteps;
----

Once the properties are configured, we can configure the subset of node properties that we want to use as features for the model

----
CALL gds.beta.pipeline.nodeClassification.selectFeatures(
    'pipe',
    ['imdbRating', 'logRuntime', 'embedding', 'degree'])
YIELD name, featureProperties;
----

After that we can configure the data splitting. In this case, it is fairly straightforward.  We configure a fraction which determines how to randomly split between test and training. Since the pipeline uses a cross-validation strategy, we can also set the number of validation folds we want here.

----
CALL gds.beta.pipeline.nodeClassification.configureSplit('pipe', {
 testFraction: 0.2,
  validationFolds: 5
})
YIELD splitConfig;
----

The final step to pipeline configuration is creating model candidates.  The pipeline is capable of running multiple models with different training methods and hyperparameter configurations. The best performing model will be selected after the training completes.


We will just add a few different logistic regressions here with different penalty hyperparameters. GDS also has a random forest model and there are more hyperparameters for each that we could adjust.  See the docs [Link TK] for more details.

----
CALL gds.beta.pipeline.nodeClassification.addLogisticRegression('pipe', {penalty: 0.0})
YIELD parameterSpace;
----

----
CALL gds.beta.pipeline.nodeClassification.addLogisticRegression('pipe', {penalty: 0.1})
YIELD parameterSpace;
----

----
CALL gds.beta.pipeline.nodeClassification.addLogisticRegression('pipe', {penalty: 1.0})
YIELD parameterSpace;
----

==== Train the Pipeline

The following command will train the pipeline. This process involves training and cross validation for all the candidate models. Selecting the best candidate according to the metric TK, then retraining on the entire training set and reporting the final performance metric from predicting on the test set.  This model is saved to the model catalog which

----
CALL gds.beta.pipeline.nodeClassification.train('proj', {
  pipeline: 'pipe',
  nodeLabels: ['TrainMovie'],
  modelName: 'nc-pipeline-model',
  targetProperty: 'cls',
  randomSeed: 7474,
  metrics: ['ACCURACY', 'F1_MACRO']
}) YIELD modelInfo
RETURN
  modelInfo.bestParameters AS winningModel,
  modelInfo.metrics.ACCURACY.train.avg AS avgTrainScore,
  modelInfo.metrics.ACCURACY.outerTrain AS outerTrainScore,
  modelInfo.metrics.ACCURACY.test AS testScore;
----

==== Predict with the Pipeline

We can predict with the following command:

----
TBD
----


== Check your understanding



[.summary]
== Summary

